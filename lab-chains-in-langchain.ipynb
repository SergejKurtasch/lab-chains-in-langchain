{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review  \\\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...   \n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...   \n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...   \n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...   \n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l...   \n",
       "\n",
       "   Review_len  \n",
       "0         492  \n",
       "1         176  \n",
       "2         690  \n",
       "3         259  \n",
       "4         416  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Review_len\"] = df[\"Review\"].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature= 0.9, model=\"gpt-5-nano\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Write a review of the product: {input_parameter}?\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here’s a balanced, generic review for a Queen Size Sheet Set that you can use or adapt if you’re reviewing a specific brand or material.\\n\\nTitle: Solid value with comfortable everyday use\\n\\nReview:\\nIf you’re shopping on a budget but don’t want to sacrifice comfort, this Queen Size Sheet Set hits a nice middle ground. The feel is soft and breathable, making it pleasant to sleep in, especially in warmer months. The fit on a standard queen mattress (60 x 80) is reliable, and the fitted sheet’s elastic and corner design keep everything in place through the night. The set typically includes a flat sheet and two standard pillowcases, all of which wash well and maintain their shape for multiple spins in the dryer.\\n\\nMaterial and feel vary by version, but for a cotton-percale option, you’ll enjoy a crisp, matte finish that won’t cling to you. If you prefer a more luxurious, silky-smooth feel, you might opt for a sateen or a higher thread count, as the percale-like options can feel a bit more “stiff” at first but tend to soften after a few washes.\\n\\nCare and durability are solid for everyday use. Following the care instructions (gentle cycle, mild detergent, low heat) helps minimize wrinkling and maintain color. The colors generally stay vibrant through several washes, though darker shades may show slight fading over time.\\n\\nPros:\\n- Good comfort for everyday sleep and in warmer climates\\n- Reliable fit on standard queen mattresses and deep-pocket variants\\n- Easy care and durable enough for regular use\\n- Budget-friendly with decent longevity\\n\\nCons:\\n- May shrink slightly after the first wash (follow care instructions to minimize)\\n- Per the feel, some sleepers may prefer a silkier or smoother fabric\\n- Deep-pocket mattresses may require a sheet with extra depth or an elastic band upgrade\\n\\nWho it’s best for:\\n- Budget-conscious shoppers seeking solid everyday sheets\\n- Guest bedrooms, kids’ rooms, or college dorms\\n- Those who prefer a crisp, breathable feel over a silky finishing\\n\\nBottom line:\\nA dependable Queen Size Sheet Set that offers comfort, decent durability, and good value for money. Ideal for daily use and guests; not the premium end of the market, but a reliable choice if you want functional sheets at a friendly price.\\n\\nIf you’d like, tell me the exact material (cotton, microfiber, bamboo, etc.), thread count, or brand, and I’ll tailor the review to that product with more precise pros and cons.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = df[\"Product\"][0]\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1, model=\"gpt-5-nano\")\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Assess the quality of the product '{product}' based on the review: {review}\\n\"\n",
    "    \"Provide a rating from 1 to 5 and justify your choice.\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"quality_assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Based on the review of '{product}': {review}\\n\"\n",
    "    \"Suggest 2-3 specific recommendations for product improvement.\"\n",
    ")\n",
    "\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"improvement_recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d5c7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 3: Response to the Review\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a polite, professional response to the customer in the same language as their review for '{product}': {review}\\n\"\n",
    "    \"Consider the tone of the review and offer a solution to the problems.\"\n",
    ")\n",
    "\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, \n",
    "                      output_key=\"customer_response\")   \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three],\n",
    "    input_variables=[\"product\", \"review\"],\n",
    "    output_variables=[\"quality_assessment\", \"improvement_recommendations\", \"customer_response\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99904364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing review 1/7: Queen Size Sheet Set\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 2/7: Waterproof Phone Pouch\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 3/7: Luxury Air Mattress\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 4/7: Pillows Insert\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 5/7: Milk Frother Handheld\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 6/7: L'Or Espresso Café \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing review 7/7: Hervidor de Agua Eléctrico\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Apply the chain to the dataset and save the results\n",
    "import time\n",
    "\n",
    "# Initialize new columns\n",
    "df['quality_assessment'] = ''\n",
    "df['improvement_recommendations'] = ''\n",
    "df['customer_response'] = ''\n",
    "\n",
    "# Apply the chain to each review\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing review {index + 1}/{len(df)}: {row['Product']}\")\n",
    "    \n",
    "    try:\n",
    "        # Run the chain\n",
    "        result = overall_chain({\n",
    "            \"product\": row['Product'],\n",
    "            \"review\": row['Review']\n",
    "        })\n",
    "        \n",
    "        # Save results to DataFrame\n",
    "        df.at[index, 'quality_assessment'] = result['quality_assessment']\n",
    "        df.at[index, 'improvement_recommendations'] = result['improvement_recommendations']\n",
    "        df.at[index, 'customer_response'] = result['customer_response']\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review {index}: {e}\")\n",
    "        df.at[index, 'quality_assessment'] = 'Processing Error'\n",
    "        df.at[index, 'improvement_recommendations'] = 'Processing Error'\n",
    "        df.at[index, 'customer_response'] = 'Processing Error'\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "811ab76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed analysis of the first review:\n",
      "==================================================\n",
      "Product: Queen Size Sheet Set\n",
      "\n",
      "Original Review: I ordered a king size set. My only criticism would be that I wish seller would offer the king size set with 4 pillowcases. I separately ordered a two pack of pillowcases so I could have a total of four. When I saw the two packages, it looked like the color did not exactly match. Customer service was excellent about sending me two more pillowcases so I would have four that matched. Excellent! For the cost of these sheets, I am satisfied with the characteristics and coolness of the sheets.\n",
      "\n",
      "Quality Assessment: Rating: 4/5\n",
      "\n",
      "Justification:\n",
      "- Positive performance: reviewer notes good characteristics and coolness, and is satisfied with the value for the price.\n",
      "- Service positively impacted the experience: excellent customer service quickly resolved the pillowcase color/matching issue by sending two more matching pillowcases.\n",
      "- A couple of drawbacks: color mismatch across pillowcase packages and confusion about sizing (ordered king instead of queen) indicate packaging/sizing quirks rather than core quality issues.\n",
      "- Overall impression: solid product quality with strong support; minor packaging and sizing issues prevent a perfect score.\n",
      "\n",
      "Improvement Recommendations: Here are 3 specific product improvement ideas based on the review:\n",
      "\n",
      "- Include four pillowcases in the king-size set (or offer a clearly labeled \"King + 4 Pillowcases\" option). This directly addresses the reviewer’s wish and avoids the need to buy a separate two-pack.\n",
      "\n",
      "- Improve color consistency and matching across components. Implement tighter dye-lot controls and batch testing to ensure pillowcases from the same order match the sheets. Offer a color-matching guarantee and easy, no-hassle replacements if a mismatch is detected.\n",
      "\n",
      "- Update product listings and packaging to set clear expectations. Show in the listing that the king set includes four pillowcases, and provide photos that depict all components together. Consider adding a color-midelity note or badge (e.g., “Same dye lot as sheet set”) to reassure customers about color match across items.\n",
      "\n",
      "Customer Response: Thank you for sharing your experience with the Queen Size Sheet Set. We’re glad to hear you’re happy with the sheets’ feel and cooling, and we’re pleased our team could quickly resolve the color-matching issue with the pillowcases.\n",
      "\n",
      "We understand you’d prefer a king-size set that includes four matching pillowcases. Your feedback is important, and we’re sharing it with our product and support teams to explore options that improve color consistency and quantity in future shipments.\n",
      "\n",
      "If you’d like, we can arrange one of the following as a courtesy to you:\n",
      "- A matching four-pillowcase set to accompany future king-size orders, or\n",
      "- A one-time replacement of pillowcases to ensure an exact color match with your current sheets.\n",
      "\n",
      "Please reply with your preferred option and any color details, and we’ll take care of it right away. Thank you again for your business and for helping us improve. If you need any further assistance, we’re here to help.\n"
     ]
    }
   ],
   "source": [
    "# Detailed look at one example\n",
    "print(\"Detailed analysis of the first review:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Product: {df.iloc[0]['Product']}\")\n",
    "print(f\"\\nOriginal Review: {df.iloc[0]['Review']}\")\n",
    "print(f\"\\nQuality Assessment: {df.iloc[0]['quality_assessment']}\")\n",
    "print(f\"\\nImprovement Recommendations: {df.iloc[0]['improvement_recommendations']}\")\n",
    "print(f\"\\nCustomer Response: {df.iloc[0]['customer_response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc5676f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with analysis results:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "      <th>quality_assessment</th>\n",
       "      <th>improvement_recommendations</th>\n",
       "      <th>customer_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "      <td>Rating: 4/5\\n\\nJustification:\\n- Positive perf...</td>\n",
       "      <td>Here are 3 specific product improvement ideas ...</td>\n",
       "      <td>Thank you for sharing your experience with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "      <td>Rating: 3/5\\n\\nJustification:\\n- Pros: The rev...</td>\n",
       "      <td>Here are 2-3 concrete improvement ideas you co...</td>\n",
       "      <td>Hello,\\n\\nThank you for sharing your experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "      <td>Rating: 1/5\\n\\nJustification:\\n- Product defec...</td>\n",
       "      <td>Here are 3 concrete, product-focused improveme...</td>\n",
       "      <td>Hi there,\\n\\nThank you for taking the time to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "      <td>Rating: 5/5\\n\\nJustification: The review is st...</td>\n",
       "      <td>Here are 2–3 concrete improvement ideas based ...</td>\n",
       "      <td>Thank you so much for your kind words! We’re t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "      <td>Rating: 2 out of 5\\n\\nJustification:\\n- The pr...</td>\n",
       "      <td>Here are 3 concrete ideas to improve the Milk ...</td>\n",
       "      <td>I'm really sorry to hear you’ve had this repea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review  \\\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...   \n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...   \n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...   \n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...   \n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l...   \n",
       "\n",
       "                                  quality_assessment  \\\n",
       "0  Rating: 4/5\\n\\nJustification:\\n- Positive perf...   \n",
       "1  Rating: 3/5\\n\\nJustification:\\n- Pros: The rev...   \n",
       "2  Rating: 1/5\\n\\nJustification:\\n- Product defec...   \n",
       "3  Rating: 5/5\\n\\nJustification: The review is st...   \n",
       "4  Rating: 2 out of 5\\n\\nJustification:\\n- The pr...   \n",
       "\n",
       "                         improvement_recommendations  \\\n",
       "0  Here are 3 specific product improvement ideas ...   \n",
       "1  Here are 2-3 concrete improvement ideas you co...   \n",
       "2  Here are 3 concrete, product-focused improveme...   \n",
       "3  Here are 2–3 concrete improvement ideas based ...   \n",
       "4  Here are 3 concrete ideas to improve the Milk ...   \n",
       "\n",
       "                                   customer_response  \n",
       "0  Thank you for sharing your experience with the...  \n",
       "1  Hello,\\n\\nThank you for sharing your experienc...  \n",
       "2  Hi there,\\n\\nThank you for taking the time to ...  \n",
       "3  Thank you so much for your kind words! We’re t...  \n",
       "4  I'm really sorry to hear you’ve had this repea...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the results\n",
    "print(\"Updated dataset with analysis results:\")\n",
    "print(\"=\" * 50)\n",
    "df[['Product', 'Review', 'quality_assessment', 'improvement_recommendations', 'customer_response']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  \"Translate the following review to German:\\n\\nReview: {review}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"german_review\" # Даем имя выходу\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following review in 1-2 sentences:\\n\\nReview: {german_review}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\" # give a name to this output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "      \"Translate the following review to Russian:\\n\\nReview: {review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"russian_review\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Here is the original review in Russian:\\n{russian_review}\\n\\nHere is its summary in German:\\n{summary}\\n\\nWrite a follow-up message to the customer in Russian, addressing their review and summary.\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"summary\", \"russian_review\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/7_xt468j3nz1xqspwcc6s8jw0000gn/T/ipykernel_40466/1992003631.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'summary': 'Der Kunde findet den Geschmack schlecht, bemerkt, dass der Schaum nicht gut hält und vermutet, dass es sich um eine alte Charge oder eine Fälschung handelt im Vergleich zu denen, die er im Laden kauft.',\n",
       " 'russian_review': 'Отзыв: Я нахожу вкус отвратительным. Пена не держится, это странно. Я покупаю те же самые в магазине, и вкус намного лучше... Старая партия или подделка!?',\n",
       " 'followup_message': 'Уважаемый клиент,\\n\\nМы приносим извинения за ваше негативное впечатление от продукции. Мы серьезно относимся к качеству нашей продукции и стремимся обеспечить клиентов только лучшими продуктами.\\n\\nМы хотели бы уточнить, что наша продукция проходит строгий контроль качества, и мы не используем старые партии или подделки. Возможно, у нас произошла непредвиденная ситуация, и мы готовы рассмотреть вашу проблему более детально.\\n\\nМы призываем вас связаться с нашим отделом обслуживания клиентов для дальнейших действий. Мы готовы выслушать вашу обратную связь и принять необходимые меры для улучшения ситуации.\\n\\nС уважением,\\nКоманда обслуживания клиентов.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"You are an excellent biologist. \\\n",
    "You have a deep understanding of living organisms, \\\n",
    "from the molecular and cellular level to entire ecosystems. \\\n",
    "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
    "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
    "You can clearly communicate how life functions and adapts, \\\n",
    "and you make connections between different biological concepts \\\n",
    "to answer challenging questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\",\n",
    "        \"description\": \"Good for answering biology questions\",\n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation is the electromagnetic radiation emitted by a perfect absorber and emitter of radiation, known as a black body. A black body absorbs all radiation that falls on it and emits radiation at all wavelengths. The spectrum of black body radiation is continuous and depends only on the temperature of the black body. This phenomenon is described by Planck's law, which states that the intensity of radiation emitted by a black body is a function of its temperature and the wavelength of the radiation.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2 + 2 is equal to 4.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the proteins that make up our cells and tissues. \\n\\nHaving DNA in every cell ensures that each cell has the necessary genetic information to carry out its specific functions and to replicate itself accurately during cell division. This ensures that the genetic information is passed on to the next generation of cells, maintaining the integrity and continuity of the organism's genetic code.\\n\\nAdditionally, DNA serves as a storage system for genetic information that can be accessed and utilized by cells as needed. This allows for the regulation of gene expression, the repair of damaged DNA, and the adaptation to changing environmental conditions.\\n\\nIn summary, every cell in our body contains DNA because it is essential for the proper functioning and survival of all living organisms.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75fd6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "history: {'input': 'Which country had the lowest amount of wars in the last 300 years?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It is difficult to determine definitively which country has had the lowest amount of wars in the last 300 years as the number of wars can vary depending on how they are defined and recorded. However, some countries that are often cited as having relatively low levels of conflict in recent history include Switzerland, Sweden, and Costa Rica. These countries have a history of neutrality and have not been involved in many major wars in the past few centuries.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Which country had the lowest amount of wars in the last 300 years?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27587f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
